{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, lit, current_date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_PATH = os.environ.get(\"TEMP\", \"C:/Temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FlaggingData\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.default.parallelism\", \"8\") \\\n",
    "    .config(\"spark.python.worker.memory\", \"512m\") \\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    "    .config(\"spark.local.dir\", TEMP_PATH) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load staging data\n",
    "\n",
    "staging_df = spark.read.csv(\"staging_data.csv\", header=True, inferSchema=True)\n",
    "final_df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+\n",
      "|customer_id|customer_name|    address|\n",
      "+-----------+-------------+-----------+\n",
      "|          1|     John Doe| 123 Elm St|\n",
      "|          2|   Jane Smith| 456 Oak St|\n",
      "|          3|    Jim Brown|789 Pine St|\n",
      "+-----------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+--------------+---------------+------------+\n",
      "|customer_id|customer_name|     address|effective_date|expiration_date|current_flag|\n",
      "+-----------+-------------+------------+--------------+---------------+------------+\n",
      "|          1|     John Doe|123 Maple St|    2024-01-01|     9999-12-31|           1|\n",
      "|          2|   Jane Smith|  456 Oak St|    2024-02-01|     9999-12-31|           1|\n",
      "+-----------+-------------+------------+--------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scd2(\n",
    "    source_df: DataFrame,\n",
    "    target_df: DataFrame,\n",
    "    join_keys: list,\n",
    "    scd_columns: list,\n",
    "    effective_date_col: str = \"effective_date\",\n",
    "    end_date_col: str = \"expiration_date\",\n",
    "    current_flag_col: str = \"current_flag\"\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Function to implement SCD2 in PySpark.\n",
    "\n",
    "    Parameters:\n",
    "    - source_df: The source DataFrame with new/updated records.\n",
    "    - target_df: The target DataFrame that maintains SCD2 history.\n",
    "    - join_keys: List of columns used for joining source and target DataFrames.\n",
    "    - scd_columns: List of columns to check for changes in source data.\n",
    "    - effective_date_col: Name of the column representing the effective date.\n",
    "    - end_date_col: Name of the column representing the end date.\n",
    "    - current_flag_col: Name of the column representing the current flag.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with updated SCD2 history.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Join keys and change condition\n",
    "    join_condition = [source_df[key] == target_df[key] for key in join_keys]\n",
    "    change_condition = None\n",
    "    for col_name in scd_columns:\n",
    "        condition = col(f\"t.{col_name}\") != col(f\"s.{col_name}\")\n",
    "        change_condition = condition if change_condition is None else change_condition | condition\n",
    "\n",
    "    # Step 2: Identify updated records\n",
    "    updated_records = (\n",
    "        source_df.alias(\"s\")\n",
    "        .join(target_df.filter(col(current_flag_col) == 1).alias(\"t\"), join_condition, how=\"inner\")\n",
    "        .filter(change_condition)\n",
    "        .select(\"t.*\")\n",
    "    )\n",
    "\n",
    "    # Expire these records in target\n",
    "    expired_records = updated_records.withColumn(\n",
    "        end_date_col, current_date()-1\n",
    "    ).withColumn(current_flag_col, lit(0))  # Change to 0 for expired records\n",
    "\n",
    "    # Prepare new versions of updated records\n",
    "    new_versions = (\n",
    "        source_df.alias(\"s\")\n",
    "        .join(updated_records.alias(\"t\"), join_condition, how=\"inner\")\n",
    "        .select(\n",
    "            \"s.*\",\n",
    "            lit(current_date()).alias(effective_date_col),\n",
    "            lit('9999-12-31').cast(\"date\").alias(end_date_col),\n",
    "            lit(1).alias(current_flag_col),  # Change to 1 for new current records\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 3: Identify new records (not in target)\n",
    "    new_records = (\n",
    "        source_df.alias(\"s\")\n",
    "        .join(target_df.alias(\"t\"), join_condition, how=\"left_anti\")\n",
    "        .select(\n",
    "            \"s.*\",\n",
    "            lit(current_date()).alias(effective_date_col),\n",
    "            lit('9999-12-31').cast(\"date\").alias(end_date_col),\n",
    "            lit(1).alias(current_flag_col),  # Change to 1 for new current records\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 4: Combine all records\n",
    "    final_df = (\n",
    "        target_df.filter(col(current_flag_col) == 1)  # Unchanged records\n",
    "        .subtract(updated_records)  # Exclude updated records\n",
    "        .union(expired_records)  # Include expired records\n",
    "        .union(new_versions)  # Include new versions of updated records\n",
    "        .union(new_records)  # Include new records\n",
    "    )\n",
    "\n",
    "    # Sort the final result\n",
    "    final_df = final_df.orderBy(\n",
    "        *join_keys,\n",
    "        col(effective_date_col).asc(),\n",
    "        col(end_date_col).asc()\n",
    "    )\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_data = apply_scd2(\n",
    "    source_df=staging_df,\n",
    "    target_df=final_df,\n",
    "    join_keys=[\"customer_id\"],\n",
    "    scd_columns=[\"customer_name\", \"address\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+--------------+---------------+------------+\n",
      "|customer_id|customer_name|     address|effective_date|expiration_date|current_flag|\n",
      "+-----------+-------------+------------+--------------+---------------+------------+\n",
      "|          1|     John Doe|123 Maple St|    2024-01-01|     2024-11-20|           0|\n",
      "|          1|     John Doe|  123 Elm St|    2024-11-21|     9999-12-31|           1|\n",
      "|          2|   Jane Smith|  456 Oak St|    2024-02-01|     9999-12-31|           1|\n",
      "|          3|    Jim Brown| 789 Pine St|    2024-11-21|     9999-12-31|           1|\n",
      "+-----------+-------------+------------+--------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scd_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+--------------+---------------+------------+\n",
      "|customer_id|customer_name|    address|effective_date|expiration_date|current_flag|\n",
      "+-----------+-------------+-----------+--------------+---------------+------------+\n",
      "|          1|     John Doe| 123 Elm St|    2024-11-21|     9999-12-31|           1|\n",
      "|          2|   Jane Smith| 456 Oak St|    2024-02-01|     9999-12-31|           1|\n",
      "|          3|    Jim Brown|789 Pine St|    2024-11-21|     9999-12-31|           1|\n",
      "+-----------+-------------+-----------+--------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scd_filter = scd_data.filter(\n",
    "    (lit('2024-11-21') >= scd_data[\"effective_date\"]) \n",
    "    & (lit('2024-11-21') <= scd_data[\"expiration_date\"])\n",
    "    & (scd_data[\"current_flag\"] == 1)\n",
    "    )\n",
    "\n",
    "scd_filter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
